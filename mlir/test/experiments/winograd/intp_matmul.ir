// ./bin/miopen-opt --cse --canonicalize ../mlir/test/experiments/winograd/intp_matmul.ir |./bin/miopen-gen -ph -rand none - | ./bin/mlir-miopen-driver -c >fully.out
// /home/rocprofiler_pkg/rocprof --stats ./bin/mlir-rocm-runner --shared-libs=/home/llvm-project-mlir/build/lib/librocm-runtime-wrappers.so,/home/llvm-project-mlir/build/external/llvm-project/llvm/lib/libmlir_runner_utils.so --entry-point-result=void ./fully.out

#map0 = affine_map<(d0, d1) -> (d0 * 2 + d1)>
#map1 = affine_map<(d0) -> (d0 * 2)>
#map2 = affine_map<(d0, d1) -> (d0 * 4 + d1)>
#map3 = affine_map<(d0) -> (d0 * 4)>
#map4 = affine_map<(d0) -> (d0 * 4 + 1)>
#map5 = affine_map<(d0) -> (d0 * 4 + 2)>
#map6 = affine_map<(d0) -> (d0 * 4 + 3)>
#map7 = affine_map<(d0) -> (d0 + 1)>
#map8 = affine_map<(d0) -> (d0 + 2)>
#map9 = affine_map<(d0) -> (d0 + 3)>
module {
  func @main0(%arg0: memref<256x28x28x128xf32>, %ft: memref<128x128x1x16xf32>, %arg1: memref<256x128x52x52xf32>) attributes {kernel} {
    %c0 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %c5 = arith.constant 5 : index
    %c6 = arith.constant 6 : index
    %c7 = arith.constant 7 : index
    %c8 = arith.constant 8 : index
    %c9 = arith.constant 9 : index
    %c10 = arith.constant 10 : index
    %c11 = arith.constant 11 : index
    %c12 = arith.constant 12 : index
    %c13 = arith.constant 13 : index
    %c14 = arith.constant 14 : index
    %c15 = arith.constant 15 : index

    %c4i = arith.constant 4 : i32
    %c8i = arith.constant 8 : i32
    %c12i = arith.constant 12 : i32
    %c0i = arith.constant 0 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : vector<4xf32>
    affine.for %arg2 = 0 to 256 {
      affine.for %arg4 = 0 to 13 {
        affine.for %arg5 = 0 to 13 {
          affine.for %arg3 = 0 to 128 {
            %lds = miopen.alloc() : memref<128x16xf32, 3>
            %acc = memref.alloca() : memref<4xvector<4xf32>>
            memref.store %cst_3, %acc[%c0] : memref<4xvector<4xf32>>
            memref.store %cst_3, %acc[%c1] : memref<4xvector<4xf32>>
            memref.store %cst_3, %acc[%c2] : memref<4xvector<4xf32>>
            memref.store %cst_3, %acc[%c3] : memref<4xvector<4xf32>>
            %lid = gpu.thread_id  x
            %0 = affine.apply #map0(%arg4, %c0)
            %1 = affine.apply #map1(%arg5)
            %2 = arith.index_cast %arg2 : index to i32
            %3 = arith.index_cast %arg3 : index to i32
            %4 = arith.index_cast %0 : index to i32
            %5 = arith.index_cast %1 : index to i32
            %6 = amdgpu.raw_buffer_load {boundsCheck = true, targetIsRDNA = false} %arg0[%2, %4, %5, %2] : memref<256x28x28x128xf32>, i32, i32, i32, i32 -> vector<4xf32>
            %9 = vector.extractelement %6[%c0 : index] : vector<4xf32>
            %12 = vector.extractelement %6[%c1 : index] : vector<4xf32>
            %15 = vector.extractelement %6[%c2 : index] : vector<4xf32>
            %18 = vector.extractelement %6[%c3 : index] : vector<4xf32>
            %21 = affine.apply #map7(%c0)
            %22 = affine.apply #map0(%arg4, %21)
            %23 = arith.index_cast %22 : index to i32
            %24 = amdgpu.raw_buffer_load {boundsCheck = true, targetIsRDNA = false} %arg0[%2, %23, %5, %3] : memref<256x28x28x128xf32>, i32, i32, i32, i32 -> vector<4xf32>
            %27 = vector.extractelement %24[%c0 : index] : vector<4xf32>
            %28 = vector.extractelement %24[%c1 : index] : vector<4xf32>
            %29 = vector.extractelement %24[%c2 : index] : vector<4xf32>
            %30 = vector.extractelement %24[%c3 : index] : vector<4xf32>
            %31 = affine.apply #map8(%c0)
            %32 = affine.apply #map0(%arg4, %31)
            %33 = arith.index_cast %32 : index to i32
            %34 = amdgpu.raw_buffer_load {boundsCheck = true, targetIsRDNA = false} %arg0[%2, %33, %5, %3] : memref<256x28x28x128xf32>, i32, i32, i32, i32 -> vector<4xf32>
            %37 = vector.extractelement %34[%c0 : index] : vector<4xf32>
            %38 = vector.extractelement %34[%c1 : index] : vector<4xf32>
            %39 = vector.extractelement %34[%c2 : index] : vector<4xf32>
            %40 = vector.extractelement %34[%c3 : index] : vector<4xf32>
            %41 = affine.apply #map9(%c0)
            %42 = affine.apply #map0(%arg4, %41)
            %43 = arith.index_cast %42 : index to i32
            %44 = amdgpu.raw_buffer_load {boundsCheck = true, targetIsRDNA = false} %arg0[%2, %43, %5, %3] : memref<256x28x28x128xf32>, i32, i32, i32, i32 -> vector<4xf32>
            %47 = vector.extractelement %44[%c0 : index] : vector<4xf32>
            %48 = vector.extractelement %44[%c1 : index] : vector<4xf32>
            %49 = vector.extractelement %44[%c2 : index] : vector<4xf32>
            %50 = vector.extractelement %44[%c3 : index] : vector<4xf32>

            //  %9 %12 %15 %18
            // %27 %28 %29 %30
            // %37 %38 %39 %40
            // %47 %48 %49 %50

// 0-8-2+10  1-9+2-10  -1+9+2-10  1-9-3+11
// 4+8-6-10  5+9+6+10  -5-9+6+10  5+9-7-11
// 8-4-10+6  9-5+10-6  -9+5+10-6  9-5-11+7
// 4-12-6+14 5-13+6-14 -5+13+6-14 5-13-7+15

            //  0-8-2+10
            %t00 = arith.subf %9, %37 : f32
            %t01 = arith.subf %t00, %15 : f32
            %out0 = arith.addf %t01, %39 : f32

            //  1-9+2-10
            %t10 = arith.subf %12, %38 : f32
            %t11 = arith.addf %t10, %15 : f32
            %out1 = arith.subf %t11, %39 : f32

            // -1+9+2-10
            %t20 = arith.subf %38, %12 : f32
            %t21 = arith.addf %t20, %15 : f32
            %out2 = arith.subf %t21, %39 : f32

            //  1-9-3+11
            %t30 = arith.subf %12, %38 : f32
            %t31 = arith.subf %t30, %18 : f32
            %out3 = arith.addf %t31, %40 : f32

            //  4+8-6-10
            %t40 = arith.addf %27, %37 : f32
            %t41 = arith.subf %t40, %29 : f32
            %out4 = arith.subf %t41, %39 : f32

            //  5+9+6+10
            %t50 = arith.addf %28, %38 : f32
            %t51 = arith.addf %t50, %29 : f32
            %out5 = arith.addf %t51, %39 : f32

            // -5-9+6+10
            %t60 = arith.addf %29, %39 : f32
            %t61 = arith.subf %t60, %28 : f32
            %out6 = arith.subf %t61, %38 : f32

            //  5+9-7-11
            %t70 = arith.addf %28, %38 : f32
            %t71 = arith.subf %t70, %30 : f32
            %out7 = arith.subf %t71, %40 : f32

            //  8-4-10+6
            %t80 = arith.subf %37, %27 : f32
            %t81 = arith.subf %t80, %39 : f32
            %out8 = arith.addf %t81, %29 : f32

            //  9-5+10-6
            %t90 = arith.subf %38, %28 : f32
            %t91 = arith.addf %t90, %39 : f32
            %out9 = arith.subf %t91, %29 : f32

            // -9+5+10-6
            %ta0 = arith.subf %28, %38 : f32
            %ta1 = arith.addf %ta0, %39 : f32
            %outa = arith.subf %ta1, %29 : f32

            //  9-5-11+7
            %tb0 = arith.subf %38, %28 : f32
            %tb1 = arith.subf %tb0, %40 : f32
            %outb = arith.addf %tb1, %30 : f32

            //  4-12-6+14
            %tc0 = arith.subf %27, %47 : f32
            %tc1 = arith.subf %tc0, %29 : f32
            %outc = arith.addf %tc1, %49 : f32

            //  5-13+6-14
            %td0 = arith.subf %28, %48 : f32
            %td1 = arith.addf %td0, %29 : f32
            %outd = arith.subf %td1, %49 : f32

            // -5+13+6-14
            %te0 = arith.subf %48, %28 : f32
            %te1 = arith.addf %te0, %29 : f32
            %oute = arith.subf %te1, %49 : f32

            //  5-13-7+15
            %tf0 = arith.subf %28, %48 : f32
            %tf1 = arith.addf %td0, %30 : f32
            %outf = arith.subf %td1, %50 : f32

            memref.store %out0, %lds[%lid, %c0] : memref<128x16xf32, 3>
            memref.store %out1, %lds[%lid, %c1] : memref<128x16xf32, 3>
            memref.store %out2, %lds[%lid, %c2] : memref<128x16xf32, 3>
            memref.store %out3, %lds[%lid, %c3] : memref<128x16xf32, 3>
            memref.store %out4, %lds[%lid, %c4] : memref<128x16xf32, 3>
            memref.store %out5, %lds[%lid, %c5] : memref<128x16xf32, 3>
            memref.store %out6, %lds[%lid, %c6] : memref<128x16xf32, 3>
            memref.store %out7, %lds[%lid, %c7] : memref<128x16xf32, 3>
            memref.store %out8, %lds[%lid, %c8] : memref<128x16xf32, 3>
            memref.store %out9, %lds[%lid, %c9] : memref<128x16xf32, 3>
            memref.store %outa, %lds[%lid, %c10] : memref<128x16xf32, 3>
            memref.store %outb, %lds[%lid, %c11] : memref<128x16xf32, 3>
            memref.store %outc, %lds[%lid, %c12] : memref<128x16xf32, 3>
            memref.store %outd, %lds[%lid, %c13] : memref<128x16xf32, 3>
            memref.store %oute, %lds[%lid, %c14] : memref<128x16xf32, 3>
            memref.store %outf, %lds[%lid, %c15] : memref<128x16xf32, 3>
 //           miopen.lds_barrier

            affine.for %arg6 = 0 to 128 {
              %100 = arith.index_cast %arg3 : index to i32
              %101 = arith.index_cast %arg6 : index to i32
              
              %102 = amdgpu.raw_buffer_load {boundsCheck = true, targetIsRDNA = false} %ft[%100, %101, %c0i, %c0i] : memref<128x128x1x16xf32>, i32, i32, i32, i32 -> vector<4xf32>
              %103 = amdgpu.raw_buffer_load {boundsCheck = true, targetIsRDNA = false} %ft[%100, %101, %c0i, %c4i] : memref<128x128x1x16xf32>, i32, i32, i32, i32 -> vector<4xf32>
              %104 = amdgpu.raw_buffer_load {boundsCheck = true, targetIsRDNA = false} %ft[%100, %101, %c0i, %c8i] : memref<128x128x1x16xf32>, i32, i32, i32, i32 -> vector<4xf32>
              %105 = amdgpu.raw_buffer_load {boundsCheck = true, targetIsRDNA = false} %ft[%100, %101, %c0i, %c12i] : memref<128x128x1x16xf32>, i32, i32, i32, i32 -> vector<4xf32>
              %106 = memref.load %lds[%arg6, %c0] : memref<128x16xf32, 3>
              %107 = memref.load %lds[%arg6, %c1] : memref<128x16xf32, 3>
              %108 = memref.load %lds[%arg6, %c2] : memref<128x16xf32, 3>
              %109 = memref.load %lds[%arg6, %c3] : memref<128x16xf32, 3>
              %110 = memref.load %lds[%arg6, %c4] : memref<128x16xf32, 3>
              %111 = memref.load %lds[%arg6, %c5] : memref<128x16xf32, 3>
              %112 = memref.load %lds[%arg6, %c6] : memref<128x16xf32, 3>
              %113 = memref.load %lds[%arg6, %c7] : memref<128x16xf32, 3>
              %114 = memref.load %lds[%arg6, %c8] : memref<128x16xf32, 3>
              %115 = memref.load %lds[%arg6, %c9] : memref<128x16xf32, 3>
              %116 = memref.load %lds[%arg6, %c10] : memref<128x16xf32, 3>
              %117 = memref.load %lds[%arg6, %c11] : memref<128x16xf32, 3>
              %118 = memref.load %lds[%arg6, %c12] : memref<128x16xf32, 3>
              %119 = memref.load %lds[%arg6, %c13] : memref<128x16xf32, 3>
              %120 = memref.load %lds[%arg6, %c14] : memref<128x16xf32, 3>
              %121 = memref.load %lds[%arg6, %c15] : memref<128x16xf32, 3>

              %122 = vector.insertelement %106, %cst_3[%c0 : index] : vector<4xf32>
              %123 = vector.insertelement %107, %122[%c1 : index] : vector<4xf32>
              %124 = vector.insertelement %108, %123[%c2 : index] : vector<4xf32>
              %125 = vector.insertelement %109, %124[%c3 : index] : vector<4xf32>

              %126 = vector.insertelement %110, %cst_3[%c0 : index] : vector<4xf32>
              %127 = vector.insertelement %111, %126[%c1 : index] : vector<4xf32>
              %128 = vector.insertelement %112, %127[%c2 : index] : vector<4xf32>
              %129 = vector.insertelement %113, %128[%c3 : index] : vector<4xf32>

              %130 = vector.insertelement %114, %cst_3[%c0 : index] : vector<4xf32>
              %131 = vector.insertelement %115, %130[%c1 : index] : vector<4xf32>
              %132 = vector.insertelement %116, %131[%c2 : index] : vector<4xf32>
              %133 = vector.insertelement %117, %132[%c3 : index] : vector<4xf32>

              %134 = vector.insertelement %118, %cst_3[%c0 : index] : vector<4xf32>
              %135 = vector.insertelement %119, %134[%c1 : index] : vector<4xf32>
              %136 = vector.insertelement %120, %135[%c2 : index] : vector<4xf32>
              %137 = vector.insertelement %121, %136[%c3 : index] : vector<4xf32>

              %138 = arith.mulf %102, %125 : vector<4xf32>
              %139 = arith.mulf %103, %129 : vector<4xf32>
              %140 = arith.mulf %104, %133 : vector<4xf32>
              %141 = arith.mulf %105, %137 : vector<4xf32>

              %142 = memref.load %acc[%c0] : memref<4xvector<4xf32>>
              %143 = memref.load %acc[%c1] : memref<4xvector<4xf32>>
              %144 = memref.load %acc[%c2] : memref<4xvector<4xf32>>
              %145 = memref.load %acc[%c3] : memref<4xvector<4xf32>>

              %146 = arith.addf %142, %138 : vector<4xf32>
              %147 = arith.addf %143, %139 : vector<4xf32>
              %148 = arith.addf %144, %140 : vector<4xf32>
              %149 = arith.addf %145, %141 : vector<4xf32>

              memref.store %146, %acc[%c0] : memref<4xvector<4xf32>>
              memref.store %147, %acc[%c1] : memref<4xvector<4xf32>>
              memref.store %148, %acc[%c2] : memref<4xvector<4xf32>>
              memref.store %149, %acc[%c3] : memref<4xvector<4xf32>>

            }

            %150 = memref.load %acc[%c0] : memref<4xvector<4xf32>>
            %151 = memref.load %acc[%c1] : memref<4xvector<4xf32>>
            %152 = memref.load %acc[%c2] : memref<4xvector<4xf32>>
            %153 = memref.load %acc[%c3] : memref<4xvector<4xf32>>

            %7 = affine.apply #map2(%arg4, %c0)
            %8 = arith.index_cast %7 : index to i32
            %10 = affine.apply #map3(%arg5)
            %11 = arith.index_cast %10 : index to i32
            amdgpu.raw_buffer_store {boundsCheck = true, targetIsRDNA = false} %150 -> %arg1[%2, %3, %8, %11] : vector<4xf32> -> memref<256x128x52x52xf32>, i32, i32, i32, i32

            %25 = affine.apply #map2(%arg4, %21)
            %26 = arith.index_cast %25 : index to i32
            amdgpu.raw_buffer_store {boundsCheck = true, targetIsRDNA = false} %151 -> %arg1[%2, %3, %26, %11] : vector<4xf32> -> memref<256x128x52x52xf32>, i32, i32, i32, i32

            %35 = affine.apply #map2(%arg4, %31)
            %36 = arith.index_cast %35 : index to i32
            amdgpu.raw_buffer_store {boundsCheck = true, targetIsRDNA = false} %152 -> %arg1[%2, %3, %36, %11] : vector<4xf32> -> memref<256x128x52x52xf32>, i32, i32, i32, i32

            %45 = affine.apply #map2(%arg4, %41)
            %46 = arith.index_cast %45 : index to i32
            amdgpu.raw_buffer_store {boundsCheck = true, targetIsRDNA = false} %153 -> %arg1[%2, %3, %46, %11] : vector<4xf32> -> memref<256x128x52x52xf32>, i32, i32, i32, i32
          }
        }
      }
    }
    return
  }
}